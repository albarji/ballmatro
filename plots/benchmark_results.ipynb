{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a90ce2",
   "metadata": {},
   "source": [
    "# Notebook to generate plots from the benchmarks results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91af309",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837540f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_COLORS = {\n",
    "    \"gpt-4.1-nano-2025-04-14\": \"#A9A8A8\",\n",
    "    \"gpt-4o-mini-2024-07-18\": \"#7a7a7a\",\n",
    "    \"gpt-4.1-mini-2025-04-14\": \"#525252\",\n",
    "    \"gpt-4o-2024-08-06\": \"#272727\",\n",
    "    \"gpt-4.1-2025-04-14\": \"#000000\",\n",
    "    \"Qwen2-0.5B-Instruct\": \"#D7A6E6\",\n",
    "    \"Qwen2.5-0.5B-Instruct\": \"#D295E4\",\n",
    "    \"Qwen2.5-1.5B-Instruct\": \"#CF88E4\",\n",
    "    \"Qwen2.5-3B-Instruct\": \"#C76EE2\",\n",
    "    \"Qwen2.5-7B-Instruct\": \"#C052E2\",\n",
    "    \"Qwen2.5-14B-Instruct\": \"#BA38E2\",\n",
    "    \"Qwen2.5-32B-Instruct\": \"#B522E1\",\n",
    "    \"Qwen3-0.6B\": \"#D7A6E6\",\n",
    "    \"gpt-oss-20b\": \"#BFBFBF\",\n",
    "    \"o4-mini-2025-04-16\": \"#666666\",\n",
    "}\n",
    "\n",
    "MODEL_PATTERNS = {\n",
    "    \"gpt-4.1-nano-2025-04-14\": \"\",\n",
    "    \"gpt-4o-mini-2024-07-18\": \"\",\n",
    "    \"gpt-4.1-mini-2025-04-14\": \"\",\n",
    "    \"gpt-4o-2024-08-06\": \"\",\n",
    "    \"gpt-4.1-2025-04-14\": \"\",\n",
    "    \"Qwen2-0.5B-Instruct\": \"\",\n",
    "    \"Qwen2.5-0.5B-Instruct\": \"\",\n",
    "    \"Qwen2.5-1.5B-Instruct\": \"\",\n",
    "    \"Qwen2.5-3B-Instruct\": \"\",\n",
    "    \"Qwen2.5-7B-Instruct\": \"\",\n",
    "    \"Qwen2.5-14B-Instruct\": \"\",\n",
    "    \"Qwen2.5-32B-Instruct\": \"\",\n",
    "    \"Qwen3-0.6B\": \"/\",\n",
    "    \"gpt-oss-20b\": \"/\",\n",
    "    \"o4-mini-2025-04-16\": \"/\",\n",
    "}\n",
    "\n",
    "MODEL_ORDER = [\n",
    "    \"Qwen2-0.5B-Instruct\",\n",
    "    \"Qwen2.5-0.5B-Instruct\",\n",
    "    \"Qwen2.5-1.5B-Instruct\",\n",
    "    \"Qwen2.5-3B-Instruct\",\n",
    "    \"Qwen2.5-7B-Instruct\",\n",
    "    \"Qwen2.5-14B-Instruct\",\n",
    "    \"Qwen2.5-32B-Instruct\",\n",
    "    \"gpt-4.1-nano-2025-04-14\",\n",
    "    \"gpt-4o-mini-2024-07-18\",\n",
    "    \"gpt-4.1-mini-2025-04-14\",\n",
    "    \"gpt-4o-2024-08-06\",\n",
    "    \"gpt-4.1-2025-04-14\",\n",
    "    \"Qwen3-0.6B\",\n",
    "    \"gpt-oss-20b\",\n",
    "    \"o4-mini-2025-04-16\"\n",
    "]\n",
    "\n",
    "MODEL_SHORT_NAMES = {\n",
    "    \"gpt-4o-mini-2024-07-18\": \"4o-mini\",\n",
    "    \"gpt-4o-2024-08-06\": \"4o\",\n",
    "    \"gpt-4.1-nano-2025-04-14\": \"4.1-nano\",\n",
    "    \"gpt-4.1-mini-2025-04-14\": \"4.1-mini\",\n",
    "    \"gpt-4.1-2025-04-14\": \"4.1\",\n",
    "    \"o4-mini-2025-04-16\": \"o4-mini\",\n",
    "    \"Qwen2-0.5B-Instruct\": \"Qwen2-0.5B\",\n",
    "    \"Qwen2.5-0.5B-Instruct\": \"Qwen2.5-0.5B\",\n",
    "    \"Qwen2.5-1.5B-Instruct\": \"Qwen2.5-1.5B\",\n",
    "    \"Qwen2.5-3B-Instruct\": \"Qwen2.5-3B\",\n",
    "    \"Qwen2.5-7B-Instruct\": \"Qwen2.5-7B\",\n",
    "    \"Qwen2.5-14B-Instruct\": \"Qwen2.5-14B\",\n",
    "    \"Qwen2.5-32B-Instruct\": \"Qwen2.5-32B\",\n",
    "    \"Qwen3-0.6B\": \"Qwen3-0.6B\",\n",
    "    \"gpt-oss-20b\": \"gpt-oss-20b\"\n",
    "}\n",
    "\n",
    "LEVEL_EXPLANATIONS = {\n",
    "    \"level1\": \"1 card\",\n",
    "    \"level2\": \"2 cards\",\n",
    "    \"level3\": \"4 cards\",\n",
    "    \"level4\": \"8 cards\",\n",
    "    \"level5\": \"8 cards, 1 of 10 jokers\",\n",
    "    \"level6\": \"8 cards, 2 of 37 jokers\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46413276",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462924b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "BENCHMARKS_FOLDER = \"../benchmarks\"\n",
    "\n",
    "def load_raw_benchmark_data():\n",
    "    \"\"\"Loads benchmark data as a dictionary from level and model name to results.\"\"\"\n",
    "    data = {}\n",
    "    for file in glob.glob(f\"{BENCHMARKS_FOLDER}/*.json\"):\n",
    "        # Get name of file without path and extension\n",
    "        name = Path(file).stem\n",
    "        level, model = name.split(\"_\")\n",
    "        with open(file, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            data[(level, model)] = json_data\n",
    "    return data\n",
    "\n",
    "def raw_data_to_dataframe(data: dict):\n",
    "    \"\"\"Converts raw benchmark data to a pandas DataFrame.\"\"\"\n",
    "    rows = []\n",
    "    for (level, model), results in data.items():\n",
    "        row = {\n",
    "            \"level\": level,\n",
    "            \"level_with_explanation\": f\"{level} ({LEVEL_EXPLANATIONS.get(level, 'Unknown')})\",\n",
    "            \"model\": model,\n",
    "            \"model_shortname\": MODEL_SHORT_NAMES.get(model, model),\n",
    "            \"model_color\": MODEL_COLORS.get(model, \"#000000\"),\n",
    "            \"model_pattern\": MODEL_PATTERNS.get(model, \"\"),\n",
    "            \"total_score\": results[\"total_score\"],\n",
    "            \"total_normalized_score\": results[\"total_normalized_score\"],\n",
    "            \"invalid_hands\": results[\"invalid_hands\"],\n",
    "            \"normalized_invalid_hands\": results[\"normalized_invalid_hands\"],\n",
    "        }\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.model = df.model.astype(\"category\")\n",
    "    df.model = df.model.cat.set_categories(MODEL_ORDER)\n",
    "    df.sort_values(by=[\"level\", \"model\"], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc159f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = load_raw_benchmark_data()\n",
    "df = raw_data_to_dataframe(raw_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421cb37f",
   "metadata": {},
   "source": [
    "## Plot performances by level an model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca30ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=[df[\"level_with_explanation\"], df[\"model_shortname\"]],\n",
    "        y=df[\"total_normalized_score\"],\n",
    "        text=[f'{x:.0%}' for x in df[\"total_normalized_score\"]],\n",
    "        marker={\n",
    "            \"color\": df[\"model_color\"],\n",
    "            \"pattern_shape\": df[\"model_pattern\"]\n",
    "        }, \n",
    "    )\n",
    ")\n",
    "fig.update_yaxes(tickformat=\",.0%\", range=[0, 1], title=\"Normalized score\")\n",
    "fig.update_xaxes(title=\"Difficulty level and model\",)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554288cd",
   "metadata": {},
   "source": [
    "Alternative plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193cc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.bar(\n",
    "    df,\n",
    "    x=\"model_shortname\",\n",
    "    y=\"total_normalized_score\",\n",
    "    color=\"model\",\n",
    "    color_discrete_map=MODEL_COLORS,\n",
    "    pattern_shape=\"model\",\n",
    "    pattern_shape_map=MODEL_PATTERNS,\n",
    "    facet_col=\"level_with_explanation\",\n",
    "    facet_col_wrap=4,\n",
    "    facet_col_spacing=0.005,\n",
    "    facet_row_spacing=0.225,\n",
    "    category_orders={\"model_shortname\": [MODEL_SHORT_NAMES[model] for model in MODEL_ORDER]},\n",
    "    barmode=\"relative\",\n",
    "    range_y=[0, 1],\n",
    "    text_auto=\",.0%\",\n",
    ")\n",
    "fig.update_yaxes(tickformat=\",.0%\", range=[0, 1], title=\"\")\n",
    "fig.update_xaxes(title=\"\", showticklabels=True)\n",
    "fig.update_layout(showlegend=False, height=700)\n",
    "for annotation in fig.layout.annotations:\n",
    "    annotation.text = annotation.text.replace(\"level_with_explanation=\", \"\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836711ec",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Add [Qwen-2.5 models](https://huggingface.co/collections/Qwen/qwen25-66e81a666513e518adb90d9e).\n",
    "* Add Qwen-3.0 reasoning models\n",
    "* Add new [open source OpenAI reasoning models](https://huggingface.co/openai/gpt-oss-20b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb43b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ballmatro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
